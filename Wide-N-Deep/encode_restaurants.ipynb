{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z715hjI0rWZW",
        "outputId": "9ce07dd0-d97b-4d28-8f28-4ffb438ca271"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from torch import nn, cat, mean"
      ],
      "metadata": {
        "id": "Nv-xviS1raKj"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read Data"
      ],
      "metadata": {
        "id": "IrPNgkAvrhgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read users pool\n",
        "involved_users = pd.read_pickle(\"/content/drive/MyDrive/yelp/sample_users.pkl\")"
      ],
      "metadata": {
        "id": "PkG7W_Wlrd0e"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "involved_users.rename(columns={\"review_count\": \"review_count_x\"}, inplace=True)"
      ],
      "metadata": {
        "id": "FAcn8D23DZVi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read restaurants pool\n",
        "restaurants = pd.read_json(\"/content/drive/MyDrive/SampleYelpData/sample_business.json\")"
      ],
      "metadata": {
        "id": "CXFqoErvrsMJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inference_process_business_data(source: pd.DataFrame):\n",
        "  # setup an array for writing each row in the csv file\n",
        "  rows = []\n",
        "  # setup an array for headers we are not using strictly\n",
        "  removed_header = ['name', 'address', 'latitude', 'longitude', 'is_open']\n",
        "  # headers that can be directly used\n",
        "  useful_header = ['business_id', 'city', 'state', 'postal_code', 'stars', 'review_count']\n",
        "  # setup an array for headers we are adding\n",
        "  business_data = source\n",
        "  # append the initial keys as csv headers\n",
        "  header = source.columns\n",
        "  business_data = business_data.drop(columns=removed_header).reset_index(drop=True)\n",
        "  orig_header = sorted(business_data.columns)\n",
        "\n",
        "  days_of_week = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
        "  attributes = [\"RestaurantsTakeOut\", 'RestaurantsReservations',\n",
        "            'RestaurantsDelivery', 'Alcohol','RestaurantsPriceRange2',\n",
        "            'OutdoorSeating','RestaurantsGoodForGroups',\n",
        "            'HasTV', 'Caters', 'GoodForKids', 'BusinessAcceptsCreditCards',\n",
        "            'WiFi']\n",
        "\n",
        "  print('processing data in the business dataset...')\n",
        "  # for every entry in the business data array\n",
        "  final_features = useful_header.copy()\n",
        "  final_features.extend(days_of_week)\n",
        "  final_features.extend(attributes)\n",
        "\n",
        "  for entry in tqdm(range(0, len(business_data))):\n",
        "    row = []\n",
        "    for item in useful_header:\n",
        "      row.append(business_data.loc[entry, item])\n",
        "\n",
        "    # iterate through the days of the week to extract the open and close times\n",
        "    for time in days_of_week:\n",
        "      flag = 0\n",
        "      # if a time is available\n",
        "      if business_data.loc[entry, 'hours'] is not None:\n",
        "        if time in business_data.loc[entry, 'hours'].keys():\n",
        "          # append the open time\n",
        "          if \"-\" in business_data.loc[entry, 'hours'][time]:\n",
        "            open_time, close_time = business_data.loc[entry, 'hours'][time].split('-')\n",
        "            if open_time != close_time:\n",
        "              flag = 1\n",
        "              row.append(1)\n",
        "      if flag == 0:\n",
        "        row.append(0)\n",
        "\n",
        "    # for each attribute that is not nested\n",
        "    for attribute in attributes:\n",
        "      # if there is an attribute\n",
        "      if business_data.loc[entry, 'attributes'] is not None:\n",
        "        if attribute in business_data.loc[entry, 'attributes'].keys():\n",
        "          # if the attribute contains true\n",
        "          if business_data.loc[entry, 'attributes'][attribute] == \"none\":\n",
        "            row.append(np.nan)\n",
        "          else:\n",
        "            row.append(business_data.loc[entry, 'attributes'][attribute])\n",
        "        else:\n",
        "          # append NA for the attribute\n",
        "          row.append(np.nan)\n",
        "      else:\n",
        "          row.append(np.nan)\n",
        "\n",
        "    # remove stray text, such as \"\\n\" form address\n",
        "    # set up an array for the cleaned row entries\n",
        "    row_clean = []\n",
        "    # for every item in the row\n",
        "    for item in row:\n",
        "      # scan and replace for nasty text\n",
        "      row_clean.append(str(item).replace('\\n', ' '))\n",
        "    # after all fields have been extracted and cleaned, append the row to the rows array for writing to csv\n",
        "    rows.append(row_clean)\n",
        "\n",
        "  new_df = pd.DataFrame(rows, columns=final_features)\n",
        "  new_df.replace({\"none\": np.nan}, inplace=True)\n",
        "\n",
        "  new_df.drop(columns = [\"state\", \"postal_code\"], inplace=True)\n",
        "  new_df.rename(columns={\"review_count\": \"review_count_y\",\n",
        "                         \"stars\": \"business_stars\"}, inplace=True)\n",
        "  new_df[\"review_count_y\"] = new_df[\"review_count_y\"].astype(int)\n",
        "  new_df[\"business_stars\"] = new_df[\"business_stars\"].astype(float)\n",
        "\n",
        "\n",
        "  return new_df"
      ],
      "metadata": {
        "id": "6UJyjTydruev"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_restaurants = inference_process_business_data(restaurants)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtLS3mPtsIRP",
        "outputId": "c26b60c7-19b3-4af3-9d4c-b58e678cb7ff"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing data in the business dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28028/28028 [00:16<00:00, 1674.94it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class WideAndDeep(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_table_shapes, # embeddings for sparse features\n",
        "        wide_size,\n",
        "        emb_size, # length of concat embeddings\n",
        "        dense_feature_size, # length of dense features\n",
        "        dropout=0.2, # dropout for embeddings\n",
        "    ):\n",
        "        super(WideAndDeep, self).__init__()\n",
        "        self.initial_cat_layer = ConcatenatedEmbeddings(\n",
        "            embedding_table_shapes, dropout=dropout\n",
        "        )\n",
        "        self.wide_linear_relu = nn.Sequential(\n",
        "            nn.Linear(wide_size, 1),\n",
        "        )\n",
        "        self.deep_linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(emb_size + dense_feature_size, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, wide_features, sparse_features, dense_features):\n",
        "        wide_res = self.wide_linear_relu(wide_features)\n",
        "        # get embeddings for sparse features\n",
        "        concat_emb = self.initial_cat_layer(sparse_features)\n",
        "        deep_input = torch.cat((concat_emb, dense_features), dim=1)\n",
        "        deep_res = self.deep_linear_relu_stack(deep_input)\n",
        "        total_res = wide_res + deep_res\n",
        "        return total_res"
      ],
      "metadata": {
        "id": "5ReoLOvAymoG"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dense_features = [\"fans\", \"average_stars\", \"starting_year\", \"friends_num\", \"useful\",\n",
        "                  \"funny\", \"cool\", \"elite_times\", \"business_stars\"]"
      ],
      "metadata": {
        "id": "wwd626DGuRP0"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wide_features = [\"review_count_x\", \"review_count_y\", 'compliment_hot',\n",
        "       'compliment_more', 'compliment_profile',\n",
        "       'compliment_cute', 'compliment_list', 'compliment_note',\n",
        "       'compliment_plain', 'compliment_cool', 'compliment_funny',\n",
        "       'compliment_writer', 'compliment_photos', 'starting_year']"
      ],
      "metadata": {
        "id": "bAARjAFPuQv0"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_features = [\n",
        "    \"city\",\n",
        "    \"RestaurantsTakeOut\",\n",
        "    'RestaurantsReservations',\n",
        "    'RestaurantsDelivery',\n",
        "    'Alcohol',\n",
        "    'RestaurantsPriceRange2',\n",
        "    'OutdoorSeating',\n",
        "    'RestaurantsGoodForGroups',\n",
        "    'HasTV',\n",
        "    'Caters',\n",
        "    'GoodForKids',\n",
        "    'BusinessAcceptsCreditCards',\n",
        "    'WiFi',\n",
        "    'Sunday',\n",
        "    'Monday',\n",
        "    'Tuesday',\n",
        "    'Wednesday',\n",
        "    'Thursday',\n",
        "    'Friday',\n",
        "    'Saturday'\n",
        "    ]"
      ],
      "metadata": {
        "id": "Lg1YDdRPttF3"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_sparse_features_idx_mapping(sparse_features, concat_df):\n",
        "  sparce_features_to_idx = defaultdict(dict)\n",
        "  idx_to_sparce_features = defaultdict(dict)\n",
        "  for f in sparse_features:\n",
        "    feature = list(concat_df[f].unique())\n",
        "    feature_nums = len(feature)\n",
        "    for i in range(feature_nums):\n",
        "      sparce_features_to_idx[f][feature[i]] = i\n",
        "      idx_to_sparce_features[f][i] = [feature[i]]\n",
        "  return sparce_features_to_idx, idx_to_sparce_features"
      ],
      "metadata": {
        "id": "E8VcWpSOj0DF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sparce_features_to_idx, idx_to_sparce_features = build_sparse_features_idx_mapping(sparse_features, parsed_restaurants)"
      ],
      "metadata": {
        "id": "72dSx0o0j0nF"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_concat_df(concat_df, sparce_features_to_idx, sparse_features):\n",
        "  encoded_concat_df = concat_df.copy()\n",
        "  for f in sparse_features:\n",
        "    encoded_concat_df[f] = encoded_concat_df[f].map(sparce_features_to_idx[f])\n",
        "  return encoded_concat_df"
      ],
      "metadata": {
        "id": "tRU8xoEXj0rK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding_shape(sparse_features, concat_df):\n",
        "  embedding_table_shapes = {}\n",
        "  for f in sparse_features:\n",
        "    if f != \"city\":\n",
        "      embedding_table_shapes[f] = (len(concat_df[f].unique()), 16)\n",
        "    else:\n",
        "      embedding_table_shapes[f] = (len(concat_df[f].unique()), 128)\n",
        "  return embedding_table_shapes"
      ],
      "metadata": {
        "id": "71QoKMQApVYn"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_table_shapes = get_embedding_shape(sparse_features, parsed_restaurants)"
      ],
      "metadata": {
        "id": "91ctgL2fpYRT"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_restaurants = encode_concat_df(parsed_restaurants, sparce_features_to_idx, sparse_features)"
      ],
      "metadata": {
        "id": "hPTtDcjwkApd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_restaurants.to_pickle(\"/content/drive/MyDrive/yelp/encoded_restaurants.pkl\")"
      ],
      "metadata": {
        "id": "IP1LgtE7EDrv"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nvtabular\n",
        "from nvtabular.framework_utils.torch.layers import ConcatenatedEmbeddings"
      ],
      "metadata": {
        "id": "Xi210plwqaS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_table_shapes = json.load(open(\"/content/drive/MyDrive/SampleYelpData/embedding_table_shapes.json\"))"
      ],
      "metadata": {
        "id": "69gCsPZC090S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = WideAndDeep(embedding_table_shapes, 14, 432, 9)\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/yelp/TrainedModel128/model_27.pt\"))"
      ],
      "metadata": {
        "id": "PnpqJmb105gV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_restaurants = pd.read_pickle(\"/content/drive/MyDrive/yelp/encoded_restaurants.pkl\")\n",
        "\n",
        "def recommend_topK(user_id, encoded_restaurants, K=10):\n",
        "  assert user_id in involved_users['user_id'].values\n",
        "  user_data = involved_users[involved_users['user_id'] == user_id].drop(columns=['user_id'])\n",
        "  assert user_data.isna().sum().sum() == 0\n",
        "  assert encoded_restaurants.isna().sum().sum() == 0\n",
        "  encoded_restaurants_ids = encoded_restaurants['business_id']\n",
        "  encoded_business_mat = encoded_restaurants.drop(columns=['business_id'])\n",
        "  user_and_business_mat = pd.concat([user_data, encoded_business_mat], axis=1)\n",
        "  user_and_business_mat = user_and_business_mat.fillna(method=\"ffill\")\n",
        "  wide_features_val, sparse_features_val, dense_features_val = user_and_business_mat[wide_features].values, user_and_business_mat[sparse_features].values, user_and_business_mat[dense_features].values\n",
        "  t_wide_features_val, t_sparse_features_val, t_dense_features_val = torch.tensor(wide_features_val).float(), torch.tensor(sparse_features_val).long(), torch.tensor(dense_features_val).float()\n",
        "  with torch.no_grad():\n",
        "    pred = model(t_wide_features_val, t_sparse_features_val, t_dense_features_val)\n",
        "    top10_idx = torch.argsort(torch.squeeze(pred), descending=True)[:10]\n",
        "    top10_idx = top10_idx.numpy()\n",
        "    top10_business_ids = encoded_restaurants_ids.iloc[top10_idx]\n",
        "    print(f\"recommend 10 restaurants for user {user_id}\")\n",
        "    for i in range(len(top10_idx)):\n",
        "      print(f\"restaurant id is {top10_business_ids.values[i]}, predicted score is {torch.squeeze(pred)[top10_idx[i]]}\")\n",
        "  # user_and_business_mat.fillna(0, inplace=True)\n",
        "  # user_and_business_mat.drop(columns=['business_id'], inplace=True\n",
        "  # print(user_data)"
      ],
      "metadata": {
        "id": "2qVbRsiWw0QK"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend_topK(\"LwZJFLGxQwjjeOgpqTJnfw\", encoded_restaurants, K=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flBR6ZbXDzGE",
        "outputId": "82ff1bbe-075e-4bc9-d6b2-a170392ddc6d"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recommend 10 restaurants for user LwZJFLGxQwjjeOgpqTJnfw\n",
            "restaurant id is _ab50qdWOk0DdB6XOrBitw, predicted score is 6.0654120445251465\n",
            "restaurant id is ac1AeYqs8Z4_e2X5M3if2A, predicted score is 6.036512851715088\n",
            "restaurant id is GXFMD0Z4jEVZBCsbPf4CTQ, predicted score is 5.762081623077393\n",
            "restaurant id is ytynqOUb3hjKeJfRj5Tshw, predicted score is 5.6587114334106445\n",
            "restaurant id is oBNrLz4EDhiscSlbOl8uAw, predicted score is 5.459670066833496\n",
            "restaurant id is VQcCL9PiNL_wkGf-uF3fjg, predicted score is 5.404573440551758\n",
            "restaurant id is _C7QiQQc47AOEv4PE3Kong, predicted score is 5.391777992248535\n",
            "restaurant id is I_3LMZ_1m2mzR0oLIOePIg, predicted score is 5.301872253417969\n",
            "restaurant id is GBTPC53ZrG1ZBY3DT8Mbcw, predicted score is 5.269805908203125\n",
            "restaurant id is gTC8IQ_i8zXytWSly3Ttvg, predicted score is 5.2371745109558105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recommend_topK(\"KVbMZV-XJPSH9wXEwuXIaA\", encoded_restaurants, K=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmtbqYr0xJAJ",
        "outputId": "d7fa0b9e-ca2f-46f2-8074-c1863bb233ae"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recommend 10 restaurants for user KVbMZV-XJPSH9wXEwuXIaA\n",
            "restaurant id is _ab50qdWOk0DdB6XOrBitw, predicted score is 5.976140022277832\n",
            "restaurant id is ac1AeYqs8Z4_e2X5M3if2A, predicted score is 5.803963661193848\n",
            "restaurant id is ytynqOUb3hjKeJfRj5Tshw, predicted score is 5.560360908508301\n",
            "restaurant id is GXFMD0Z4jEVZBCsbPf4CTQ, predicted score is 5.216649055480957\n",
            "restaurant id is oBNrLz4EDhiscSlbOl8uAw, predicted score is 5.112929344177246\n",
            "restaurant id is GBTPC53ZrG1ZBY3DT8Mbcw, predicted score is 5.076563358306885\n",
            "restaurant id is VQcCL9PiNL_wkGf-uF3fjg, predicted score is 5.0743489265441895\n",
            "restaurant id is I_3LMZ_1m2mzR0oLIOePIg, predicted score is 4.960506916046143\n",
            "restaurant id is _C7QiQQc47AOEv4PE3Kong, predicted score is 4.957914352416992\n",
            "restaurant id is iSRTaT9WngzB8JJ2YKJUig, predicted score is 4.947678089141846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recommend_topK(\"BgZwJBhVWKq1Urs4rKBdiA\", encoded_restaurants, K=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkfJivgvxSbp",
        "outputId": "b609696d-db7d-40f0-b778-d7ee5ec9f809"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recommend 10 restaurants for user BgZwJBhVWKq1Urs4rKBdiA\n",
            "restaurant id is _ab50qdWOk0DdB6XOrBitw, predicted score is 6.031673431396484\n",
            "restaurant id is ac1AeYqs8Z4_e2X5M3if2A, predicted score is 5.9640069007873535\n",
            "restaurant id is GXFMD0Z4jEVZBCsbPf4CTQ, predicted score is 5.585503101348877\n",
            "restaurant id is ytynqOUb3hjKeJfRj5Tshw, predicted score is 5.518928527832031\n",
            "restaurant id is oBNrLz4EDhiscSlbOl8uAw, predicted score is 5.36427640914917\n",
            "restaurant id is iSRTaT9WngzB8JJ2YKJUig, predicted score is 5.334163665771484\n",
            "restaurant id is VQcCL9PiNL_wkGf-uF3fjg, predicted score is 5.325367450714111\n",
            "restaurant id is _C7QiQQc47AOEv4PE3Kong, predicted score is 5.264368534088135\n",
            "restaurant id is GBTPC53ZrG1ZBY3DT8Mbcw, predicted score is 5.2140583992004395\n",
            "restaurant id is 6a4gLLFSgr-Q6CZXDLzBGQ, predicted score is 5.155121803283691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import json\n",
        "# with open(\"/content/drive/MyDrive/SampleYelpData/embedding_table_shapes.json\", \"w\") as outfile:\n",
        "#     json.dump(embedding_table_shapes, outfile)"
      ],
      "metadata": {
        "id": "OqcpBSHcsanb"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = WideAndDeep(embedding_table_shapes, 14, 432, 9)\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/yelp/TrainedModel128/model_27.pt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QG5cHDoot5d",
        "outputId": "b132dadb-96ce-4c29-a7f5-da9cc7a6e2bd"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    }
  ]
}